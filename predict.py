import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
import segmentation_models_pytorch as smp
import os
import traceback

# ================= é…ç½®åŒºåŸŸ =================
# === ä¿®æ”¹ç‚¹ 0: å¿…é¡»åŠ è½½é‚£ä¸ªæ–°çš„ 5åˆ†ç±»æ¨¡åž‹ ===
MODEL_PATH = './best_model_camvid_5classes.pth'

# æµ‹è¯•å›¾ç‰‡
# IMAGE_PATH = './test02.jpeg'
IMAGE_PATH = './0016E5_04350.png'

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
INPUT_HEIGHT = 384
INPUT_WIDTH = 480

# === ä¿®æ”¹ç‚¹ 1: é¢œè‰²å®šä¹‰å¢žåŠ  ID=4 (è“è‰²) ===
# 0=èƒŒæ™¯, 1=è·¯(ç»¿), 2=äºº(é»„), 3=è½¦(çº¢), 4=éª‘è¡Œè€…(è“)
CLASS_COLORS = {
    0: (0, 0, 0),  # èƒŒæ™¯
    1: (0, 255, 0),  # è·¯
    2: (255, 255, 0),  # äºº
    3: (255, 0, 0),  # è½¦
    4: (0, 0, 255)  # éª‘è¡Œè€… (è“)
}


def colorize_mask(class_map):
    colored = np.zeros((class_map.shape[0], class_map.shape[1], 3), dtype=np.uint8)
    for id, color in CLASS_COLORS.items():
        colored[class_map == id] = color
    return colored


if __name__ == '__main__':
    os.environ['HF_HUB_OFFLINE'] = '1'
    print(f"ðŸš€ è®¾å¤‡: {DEVICE}")
    print(f"ðŸ“‚ åŠ è½½æ¨¡åž‹: {MODEL_PATH}")

    try:
        map_loc = None if torch.cuda.is_available() else 'cpu'
        loaded_obj = torch.load(MODEL_PATH, map_location=map_loc, weights_only=False)

        # === ä¿®æ”¹ç‚¹ 2: éª¨æž¶ä¹Ÿè¦æ”¹æˆ 5 ç±» ===
        model = smp.DeepLabV3Plus(
            encoder_name='mobilenet_v2',
            encoder_weights=None,
            classes=5,  # ðŸ‘ˆ å¿…é¡»æ˜¯ 5
            activation=None
        )

        if isinstance(loaded_obj, dict):
            state_dict = loaded_obj
        else:
            state_dict = loaded_obj.state_dict()

        model.load_state_dict(state_dict)
        print("âœ… æ¨¡åž‹åŠ è½½æˆåŠŸï¼")

    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ '{MODEL_PATH}'")
        print("è¯·å…ˆè¿è¡Œ train.py è®­ç»ƒå‡ºæ–°æ¨¡åž‹ï¼")
        exit()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        traceback.print_exc()
        exit()

    model.to(DEVICE)
    model.eval()

    # è¯»å–ä¸Žé¢„å¤„ç†
    image = cv2.imread(IMAGE_PATH)
    if image is None:
        print(f"âŒ æ‰¾ä¸åˆ°å›¾ç‰‡: {IMAGE_PATH}")
        exit()
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(image, (INPUT_WIDTH, INPUT_HEIGHT))

    try:
        prep_fn = smp.encoders.get_preprocessing_fn('mobilenet_v2', 'imagenet')
        img_prep = prep_fn(img_resized)
    except:
        img_prep = img_resized / 255.0

    img_prep = img_prep.transpose(2, 0, 1).astype('float32')
    tensor = torch.from_numpy(img_prep).unsqueeze(0).to(DEVICE)

    # æŽ¨ç†
    print("ðŸ¤– æ­£åœ¨æŽ¨ç†...")
    with torch.no_grad():
        output = model(tensor)
        pred = np.argmax(output.squeeze().cpu().numpy(), axis=0)

    # ç»“æžœ
    unique_classes = np.unique(pred)
    print(f"ðŸ” æ£€æµ‹ç»“æžœç±»åˆ« ID: {unique_classes}")

    colored_mask = colorize_mask(pred)
    mask_bool = (pred > 0)[:, :, None]
    blended = np.where(mask_bool, img_resized * 0.6 + colored_mask * 0.4, img_resized)

    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(img_resized)
    plt.axis('off')
    plt.subplot(1, 2, 2)
    plt.imshow(blended.astype(np.uint8))
    plt.axis('off')
    plt.show()